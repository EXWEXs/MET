////////////////////////////////////////////////////////////////////////////////
//
// Configuration file overview.
//
////////////////////////////////////////////////////////////////////////////////

The configuration files that control many of the MET tools contain formatted
ASCII text.  This format has been updated for METv4.0.

Settings common to multiple tools are described in the top part of this README
file and settings specific to individual tools are described beneath the common
settings.  Please refer to the MET User's Guide in the "doc" directory for more
details about the settings if necessary.

A configuration file entry is an entry name, followed by an equal sign =,
followed by an entry value, and is terminated by a semicolon ;.  The
configuration file itself is one large dictionary consisting of entries, some of
which are dictionaries themselves.

The configuration file language supports the following data types:
   - Dictionary:
      - Grouping of one or more entries enclosed by curly braces {}.
   - Array:
      - List of one or more entries enclosed by square braces [].
      - Array elements are separated by commas.
   - String:
      - A character string enclosed by double quotation marks "".
   - Integer:
      - A numeric integer value.
   - Float:
      - A numeric float value.
   - Boolean:
      - A boolean value (TRUE or FALSE).
   - Threshold:
      - A threshold type (<, <=, ==, !-, >=, or >) followed by a numeric value.
      - The threshold type may also be specified using two letter abbreviations
        (lt, le, eq, ne, ge, gt).
   - Piecewise-Linear Function (currently used only by MODE):
      - A list of (x, y) points enclosed in parenthesis ().
      - The (x, y) points are *NOT* separated by commas.

The context of a configuration entry matters.  If an entry cannot be found in
the expected dictionary, the MET tools recursively search for that entry in the
parent dictionaries, all the way up to the top-level configuration file
dictionary.  If you'd like to apply the same setting across all cases, you can
simply specify it once at the top-level.  Alternatively, you can specify a
setting at the appropriate dictionary level to have finer control over the
behavior.

In order to make the configuration files more readable, several descriptive
integer types have been defined in the ConfigConstants file.  These integer
names may be used on the right-hand side for many configuration file entries.

Each of the configurable MET tools expects a certain set of configuration
entries.  Examples of the MET configuration files can be found in data/config
and scripts/config.

When you pass a configuration file to a MET tool, the tool actually parses three
different configuration files in the following order:
   (1) Reads data/config/ConfigConstants to define constants.
   (2) Reads the default configuration file for the tool from data/config.
   (3) Reads the user-specified configuration file from the command line.

Many of the entries from step (2) are overwritten by the user-specified entries
from step (3).  Therefore, the configuration file you pass in on the command
line really only needs to contain entries that differ from the defaults.

The configuration file language supports the use of environment variables. When
scripting up many calls to the MET tools, you may find it convenient to use them.
They are specified as ${ENV_VAR}, where ENV_VAR is the name of the environment
variable.

The MET_BASE variable is defined in the code at compilation time as the path
to the MET shared data.  These are things like the default configuration files,
common polygons and color scales.  MET_BASE may be used in the MET configuration
files when specifying paths and the appropriate path will be substituted in.
If MET_BASE is defined as an environment variable, its value will be used
instead of the one defined at compilation time.

An error in the syntax of a configuration file will result in an error from the
MET tool stating the location of the parsing error.

////////////////////////////////////////////////////////////////////////////////
//
// Configuration settings used by the MET tools.
//
////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////
//
// Settings common to multiple tools
//
////////////////////////////////////////////////////////////////////////////////

//
// The "exit_on_warning" entry in ConfigConstants may be set to true or false.
// If set to true and a MET tool encounters a warning, it will immediately exit
// with bad status after writing the warning message.
//
exit_on_warning = FALSE;

//
// The "output_precision" entry in ConfigConstants defines the precision
// (number of significant decimal places) to be written to the ASCII output
// files.  Setting this option in the config file of one of the tools will
// override the default value set in ConfigConstants.
//
output_precision = 5;

//
// The "model" entry specifies a name for the model being verified.  This name
// is written to the MODEL column of the ASCII output generated.  If you're
// verifying multiple models, you should choose descriptive model names (no
// whitespace) to distinguish between their output.
// e.g. model = "GFS";
//
model = "WRF";

//
// The "obtype" entry specifies a name to describe the type of verifying gridded
// observation used.  This name is written to the OBTYPE column in the ASCII
// output generated.  If you're using multiple types of verifying observations,
// you should choose a descriptive name (no whitespace) to distinguish between
// their output.  When verifying against point observations the point
// observation message type value is written to the OBTYPE column.  Otherwise,
// the configuration file obtype value is written.
//
obtype = "ANALYS";

//
// The "regrid" entry is a dictionary containing information about how to handle
// input gridded data files.  The "regrid" entry specifies regridding logic
// using the following entries:
//
//   - The "to_grid" entry may be set to NONE, FCST, OBS, a named grid, the path
//     to a gridded data file defining the grid, or an explicit grid specification
//     string.
//      - to_grid = NONE;   To disable regridding.
//      - to_grid = FCST;   To regrid observations to the forecast grid.
//      - to_grid = OBS;    To regrid forecasts to the observation grid.
//      - to_grid = "G218"; To regrid both to a named grid.
//      - to_grid = "path"; To regrid both to a grid defined by a file.
//      - to_grid = "spec"; To define a grid specified as follows:
//         - lambert Nx Ny lat_ll lon_ll lon_orient D_km R_km standard_parallel_1
//           [standard_parallel_2]
//         - stereo Nx Ny lat_ll lon_ll lon_orient D_km R_km lat_scale N|S
//         - latlon Nx Ny lat_ll lon_ll delta_lat delta_lon
//         - mercator Nx Ny lat_ll lon_ll lat_ur lon_ur
//
//    - The "vld_thresh" entry specifies a proportion between 0 and 1 to define
//      the required ratio of valid data points.  When regridding, compute
//      a ratio of the number of valid data points to the total number of
//      points in the neighborhood.  If that ratio is less than this threshold,
//      write bad data for the current point.
//
//   - The "method" entry defines the regridding method to be used.
//      - Valid regridding methods:
//        MIN, MAX, MEDIAN, UW_MEAN, DW_MEAN, LS_FIT, BILIN, NEAREST, BUDGET
//
//   - The "width" entry specifies a regridding width, when applicable.
//      - width = 4;        To regrid using a 4x4 box.
//
regrid = {
   to_grid    = NONE;
   vld_thresh = 0.5;
   method     = NEAREST;
   width      = 1;
};

//
// The "fcst" entry is a dictionary containing information about the field(s)
// to be verified.  This dictionary may include the following entries:
//
//   - The "field" entry is an array of dictionaries, each specifying a
//     verification task.  Each of these dictionaries may include:
//
//      - The "name" entry specifies a name for the field.
//
//      - The "level" entry specifies level information for the field.
//
//      - Setting "name" and "level" is file-format specific.  See below.
//
//      - The "prob" entry is a boolean that specifies whether this field
//        contains probabilities.
//
//      - The "cat_thresh" entry is an array of thresholds to be used when
//        computing categorical statistics.
//
//      - The "cnt_thresh" entry is an array of thresholds for filtering
//        data prior to computing continuous statistics and partial sums.
//
//      - The "cnt_logic" entry may be set to UNION, INTERSECTION, or SYMDIFF
//        and controls the logic for how the forecast and observed cnt_thresh
//        settings are combined when filtering matched pairs of forecast and
//        observed values.
//
//   - The "file_type" entry specifies the input file type rather than letting
//     the code determine it itself.  For valid file_type values, see "File types"
//     in the data/config/ConfigConstants file.
//
//   - The "wind_thresh" entry is an array of thresholds used to filter wind
//     speed values when computing VL1L2 vector partial sums.  Only those U/V
//     pairs that meet this wind speed criteria will be included in the sums.
//     Setting this threshold to NA will result in all U/V pairs being used.
//
//   - The "wind_logic" entry may be set to UNION, INTERSECTION, or SYMDIFF
//     and controls the logic for how the forecast and observed wind_thresh
//     settings are combined when filtering matched pairs of forecast and
//     observed wind speeds.
//
//   - The "init_time" entry specifies the initialization time in YYYYMMDD[_HH[MMSS]]
//     format.  This entry can be included in the "fcst" entry as shown below or
//     included in the "field" entry if the user would like to use different
//     initialization times for different fields.
//
//   - The "valid_time" entry specifies the valid time in YYYYMMDD[_HH[MMSS]]
//     format.  This entry can be included in the "fcst" entry as shown below or
//     included in the "field" entry if the user would like to use different
//     valid times for different fields.
//
//   - The "lead_time" entry specifies the lead time in HH[MMSS]
//     format.  This entry can be included in the "fcst" entry as shown below or
//     included in the "field" entry if the user would like to use different
//     lead times for different fields.
//
// It is only necessary to use the "init_time", "valid_time", and/or "lead_time"
// settings when verifying a file containing data for multiple output times.
// For example, to verify a GRIB file containing data for many lead times, you
// could use "lead_time" to specify the record to be verified.
//
// File-format specific settings for the "field" entry:
//
//    - GRIB1 and GRIB2:
//       - The "name" entry specifies a GRIB code number or abbreviation.
//         http://www.nco.ncep.noaa.gov/pmb/docs/on388/table2.html
//       - The "level" entry specifies a level type and value:
//          - ANNN for accumulation interval NNN
//          - ZNNN for vertical level NNN
//          - ZNNN-NNN for a range of vertical levels
//          - PNNN for pressure level NNN in hPa
//          - PNNN-NNN for a range of pressure levels in hPa
//          - LNNN for a generic level type
//          - RNNN for a specific GRIB record number
//       - The "GRIB_lvl_typ" entry specifies the level type.
//       - The "GRIB_lvl_val1" and "GRIB_lvl_val2" entries specify the first
//         and second level values.
//       - The "GRIB1_ptv" entry specifies the GRIB1 parameter table version
//         number.
//       - The "GRIB1_rec" entry specifies the GRIB1 record number.
//       - The "GRIB2_disc" entry specifies the GRIB2 discipline code.
//       - The "GRIB2_parm_cat" entry specifies the parameter category code.
//       - The "GRIB2_parm" entry specifies the parameter code.
//
//    - NetCDF (from MET tools and Pinterp):
//       - The "name" entry specifies the NetCDF variable name.
//       - The "level" entry specifies the dimensions to be used:
//          - (i,...,j,*,*) for a single field, where i,...,j specifies fixed
//            dimension values and *,* specifies the two dimensions for the
//            gridded field.
//       e.g.
//           field = [
//             {
//               name       = "QVAPOR";
//               level      = "(0,5,*,*)";
//             },
//             {
//               name       = "TMP_P850_ENS_MEAN";
//               level      = [ "(*,*)" ];
//             }
//
//           ];
//
//
fcst = {
   cnt_thresh   = [ NA ];
   cnt_logic    = UNION;
   wind_thresh  = [ NA ];
   wind_logic   = UNION;
   message_type = [ "ADPSFC" ];
   init_time    = "20120619_12";
   valid_time   = "20120620_00";
   lead_time    = "12";

   field = [
      {
        name       = "APCP";
        level      = [ "A03" ];
        cat_thresh = [ >0.0, >=5.0 ];
      }
   ];
};

//
// The "obs" entry specifies the same type of information as "fcst", but for
// the observation data.  It will often be set to the same things as "fcst",
// as shown in the example below.  However, when comparing forecast and
// observation files of different format types, this entry will need to be set
// in a non-trivial way.  The length of the "obs.field" array must match the
// length of the "fcst.field" array.
//     e.g.
//         obs = fcst;
//
//     or
//
//         fcst = {
//           cnt_thresh  = [ NA ];
//           cnt_logic   = UNION;
//           wind_thresh = [ NA ];
//           wind_logic  = UNION;
//
//           field = [
//              {
//                 name       = "PWAT";
//                 level      = [ "L0" ];
//                 cat_thresh = [ >2.5 ];
//              }
//            ];
//         }
//
//
//         obs = {
//           cnt_thresh  = [ NA ];
//           cnt_logic   = UNION;
//           wind_thresh = [ NA ];
//           wind_logic  = UNION;
//
//           field = [
//              {
//                 name       = "IWV";
//                 level      = [ "L0" ];
//                 cat_thresh = [ >25.0 ];
//              }
//            ];
//         }
//
//
//   - The "message_type" entry is an array of point observation message types
//     to be used.  This only applies to the tools that verify against point
//     observations.  This may be specified once at the top-level "obs"
//     dictionary or separately for each "field" array element.  In the example
//     shown above, this is specified in the "fcst" dictionary and copied to "obs".
//   - The "message_type" would be placed in the "field" array element if more
//     than one "message_type" entry is desired within the config file.
//     e.g.
//     fcst = {
//       cnt_thresh  = [ NA ];
//       cnt_logic   = UNION;
//       wind_thresh = [ NA ];
//       wind_logic  = UNION;
//
//       field = [
//          {
//            message_type = [ "ADPUPA" ];
//            sid_exc      = [];
//            name       = "TMP";
//            level      = [ "P250", "P500", "P700", "P850", "P1000" ];
//            cat_thresh = [ <=273.0 ];
//          },
//          {
//            message_type = [ "ADPSFC" ];
//            sid_exc      = [ "KDEN", "KDET" ];
//            name       = "TMP";
//            level      = [ "Z2" ];
//            cat_thresh = [ <=273.0 ];
//          }
//       ];
//     }

//    - The "sid_exc" entry is an array of station ID groups indicating which
//      station ID's should be excluded from the verification tasks.  Each element
//      is either the name of a single station ID or a station ID group file name.
//      A station ID group file consists of a name for the group followed by a
//      list of station ID's.  All of the station ID's indicated will be placed
//      into one long list of station ID's to be excluded.
//    - As with "message_type" above, the "sid_exc" setting can be placed in the
//      in the "field" array element to control which station ID's are excluded
//      for each verification task.
//
obs = fcst;

//
// The "climo_mean" dictionary specifies climatology data to read by the
// Grid-Stat, Point-Stat, and Ensemble-Stat tools.  It consists of several
// entires defining the climatology file names and fields to be used.
//
//   - The "file_names" entry specifies one or more file names containing
//     the gridded climatology data to be used.
//
//   - The "field" entry is an array of dictionaries, specified the same
//     way as those in the "fcst" and "obs" dictionaries.  If the array has
//     length zero, not climatology data will be read and all climatology
//     statistics will be written as missing data.  Otherwise, the array
//     length must match the length of "field" in the "fcst" and "obs"
//     dictionaries.
//
//   - The "regrid" dictionary defines how the climatology data should be
//     regridded to the verification domain.
//
//   - The "time_interp_method" entry specifies how the climatology data should
//     be interpolated in time to the forecast valid time:
//      - NEAREST for data closest in time
//      - UW_MEAN for average of data before and after
//      - DW_MEAN for linear interpolation in time of data before and after
//
//   - The "match_day" entry may be set to TRUE or FALSE.  When searching
//     climatology data, only consider times where the month matches the
//     forecast valid month.  Set match_day to TRUE or FALSE to define whether
//     the climatology day must also match.
//      - match_day = FALSE for monthly climatology
//      - match_day = TRUE  for daily climatology
//
//   - The "time_step" entry specifies the spacing of climatology data in
//     seconds.  Set to 60*60*6 = 21600 for 6-hourly data or 60*60 = 3600
//     for hourly data.
//
climo_mean = {

   file_name = [];
   field     = [];

   regrid = {
      vld_thresh = 0.5;
      method     = NEAREST;
      width      = 1;
   }

   time_interp_method = DW_MEAN;
   match_day          = FALSE;
   time_step          = 21600;
}

//
// The "mask_missing_flag" entry specifies how missing data should be handled
// in the Wavelet-Stat and MODE tools:
//    - "NONE" to perform no masking of missing data
//    - "FCST" to mask the forecast field with missing observation data
//    - "OBS" to mask the observation field with missing forecast data
//    - "BOTH" to mask both fields with missing data from the other
//
mask_missing_flag = BOTH;

//
// The "obs_window" entry is a dictionary specifying a beginning ("beg"
// entry) and ending ("end" entry) time offset values in seconds.  It defines
// the time window over which observations are retained for scoring. These time
// offsets are defined relative to a reference time t, as [t+beg, t+end].
// In PB2NC, the reference time is the PrepBufr files center time.  In
// Point-Stat and Ensemble-Stat, the reference time is the forecast valid time.
//
obs_window = {
   beg = -5400;
   end =  5400;
}

//
// The "mask" entry is a dictionary that specifies the verification masking
// regions to be used when computing statistics.  Each mask defines a
// geographic extent, and any matched pairs falling inside that area will be
// used in the computation of statistics.  Masking regions may be specified
// in the following ways:
//
//    - The "grid" entry is an array of named grids.  An empty list indicates
//      that no masking grids should be used.  The standard NCEP grids are
//      named "GNNN" where NNN indicates the three digit grid number.  Enter
//      "FULL" to score over the entire domain.
//      http://www.nco.ncep.noaa.gov/pmb/docs/on388/tableb.html
//
//    - The "poly" entry is an array of masking regions that may be specified
//      in the following ways:
//
//       - An ASCII file containing a lat/lon polygon.
//         Latitude in degrees north and longitude in degrees east.
//         By default, the first and last polygon points are connected.
//         e.g. "MET_BASE/poly/EAST.poly" which consists of n points:
//              "poly_name lat1 lon1 lat2 lon2... latn lonn"
//
//       - The NetCDF output of the gen_vx_mask tool.
//
//       - A gridded data file on the same grid as the forecast data followed
//         by a dictionary for the field to be used, and optionally, a
//         threshold to be applied.
//         e.g. "sample.grib {name = \"TMP\"; level = \"Z2\";} >273"
//
//    - The "sid" entry is an array of station ID groups.  Each element is
//      either the name of a single station ID or a station ID group file name.
//      A station ID group file consists of a name for the group followed by a
//      list of station ID's.
//
mask = {
   grid    = [ "FULL" ];
   poly    = [ "MET_BASE/poly/LMV.poly",
               "MET_BASE/out/gen_vx_mask/CONUS_poly.nc",
               "MET_BASE/sample_fcst/2005080700/wrfprs_ruc13_12.tm00_G212 \
               {name = \"TMP\"; level = \"Z2\";} >273"
             ];
   sid     = [ "CONUS.stations" ];
};

//
// The "ci_alpha" entry is an array of floats specifying the values for alpha
// to be used when computing confidence intervals.  Values of alpha must be
// between 0 and 1.  A value of 0.05 corresponds to a 95% confidence interval.
//
ci_alpha = [ 0.05, 0.10 ];

//
// The "boot" entry is a dictionary that specifies how bootstrap confidence
// intervals should be computed.  This dictionary may include the following
// entries:
//
//    - The "interval" entry specifies the confidence interval method:
//       - "BCA" for the BCa interval method is more accurate but slower.
//       - "PCTILE" uses the percentile method and is quicker.
//
//    - The "rep_prop" entry specifies a proportion between 0 and 1 to define
//      the replicate sample size to be used when computing percentile
//      intervals.  The replicate sample size is set to boot_rep_prop * n,
//      where n is the number of raw data points.
//
//    - The "n_rep" entry specifies the number of bootstrap replicates.  That
//      is the number of times each set of matched pair data should be
//      resampled when computing bootstrap confidence intervals.  A value of
//      zero disables the computation of bootstrap confidence intervals and
//      may speed up the runtime significantly.
//
//    - The "rng" entry specifies the name of the GSL random number generator.
//      http://www.gnu.org/software/gsl/manual/html_node/Random-Number-Generator-Performance.html
//
//    - The "seed" entry specifies a seed value to be used when computing
//      bootstrap confidence intervals.  If left unspecified, the seed will
//      change for each run and the computed bootstrap confidence intervals
//      will not be reproducible.
//
boot = {
   interval = PCTILE;
   rep_prop = 1.0;
   n_rep    = 0;
   rng      = "mt19937";
   seed     = "";
};

//
// The "interp" entry is a dictionary that specifies what interpolation methods
// should be applied.  This dictionary may include the following entries:
//
//    - The "field" entry specifies to which field(s) the interpolation method
//      should be applied:
//       - "FCST" to interpolate/smooth the forecast field.
//       - "OBS" to interpolate/smooth the observation field.
//       - "BOTH" to interpolate/smooth both the forecast and the observation.
//
//    - The "vld_thresh" entry specifies a proportion between 0 and 1 to define
//      the required ratio of valid data points.  When interpolating, compute
//      a ratio of the number of valid data points to the total number of
//      points in the neighborhood.  If that ratio is less than this threshold,
//      skip the current point.
//
//    - The "type" entry is an array of dictionaries, each specifying an
//      interpolation method.  Interpolation is performed over a N by N box
//      centered on each point, where N is the width specified.  Each of these
//      dictionaries must include:
//
//      - The "width" entry specifies dimension of the interpolation box. For
//        grid-to-grid comparisons, the width must be odd.
//
//      - The "method" entry specifies the interpolation procedure to be
//        applied to the points in the box:
//           - "MIN" for the minimum value
//           - "MAX" for the maximum value
//           - "MEDIAN" for the median value
//           - "UW_MEAN" for the unweighted average value
//           - "DW_MEAN" for the distance-weighted average value
//           - "LS_FIT" for a least-squares fit
//           - "BILIN" for bilinear interpolation
//           - For grid-to-grid comparisons, only valid options are MIN, MAX,
//             MEDIAN, and UW_MEAN are options.
//
interp = {
   field      = BOTH;
   vld_thresh = 1.0;

   type = [
      {
         method = UW_MEAN;
         width  = 1;
      }
   ];
};

//
// The "nbrhd" entry is a dictionary that is very similar to the "interp"
// entry.  It specifies information for computing neighborhood statistics in
// Grid-Stat.  This dictionary may include the following entries:
//
//    - The "vld_thresh" entry is described above.
//
//    - The "width" entry is as described above, and must be odd.
//
//    - The "cov_thresh" entry is an array of thresholds to be used when
//      computing categorical statistics for the neighborhood fractional
//      coverage field.
//
nbrhd = {
   vld_thresh = 1.0;
   width      = [ 1 ];
   cov_thresh = [ >=0.5 ];
}

//
// The "output_flag" entry is a dictionary that specifies what verification
// methods should be applied to the input data.  Options exist for each
// output line type from the MET tools.  Each line type may be set to one of:
//    - "NONE" to skip the corresponding verification method
//    - "STAT" to write the verification output only to the ".stat" output file
//    - "BOTH" to write to the ".stat" output file as well the optional
//      "_type.txt" file, a more readable ASCII file sorted by line type.
//
output_flag = {
   fho    = BOTH;  // Forecast, Hit, Observation Rates
   ctc    = BOTH;  // Contingency Table Counts
   cts    = BOTH;  // Contingency Table Statistics
   mctc   = BOTH;  // Multi-category Contingency Table Counts
   mcts   = BOTH;  // Multi-category Contingency Table Statistics
   cnt    = BOTH;  // Continuous Statistics
   sl1l2  = BOTH;  // Scalar L1L2 Partial Sums
   sal1l2 = BOTH;  // Scalar Anomaly L1L2 Partial Sums when climatological data is supplied
   vl1l2  = BOTH;  // Vector L1L2 Partial Sums
   val1l2 = BOTH;  // Vector Anomaly L1L2 Partial Sums when climatological data is supplied
   pct    = BOTH;  // Contingency Table Counts for Probabilistic Forecasts
   pstd   = BOTH;  // Contingency Table Statistics for Probabilistic Forecasts with Dichotomous outcomes
   pjc    = BOTH;  // Joint and Conditional Factorization for Probabilistic Forecasts
   prc    = BOTH;  // Receiver Operating Characteristic for Probabilistic Forecasts
   mpr    = BOTH;  // Matched Pair Data
   nbrctc = BOTH;  // Neighborhood Contingency Table Counts
   nbrcts = BOTH;  // Neighborhood Contingency Table Statistics
   nbrcnt = BOTH;  // Neighborhood Continuous Statistics
   isc    = BOTH;  // Intensity-Scale
   rhist  = BOTH;  // Rank Histogram
   phist  = BOTH;  // Probability Integral Transform Histogram
   orank  = BOTH;  // Observation Rank
   ssvar  = BOTH;  // Spread Skill Variance
};

//
// The "nc_pairs_flag" can be set either to a boolean value or a dictionary
// in either Grid-Stat, Wavelet-Stat or MODE. The dictionary (with slightly
// different entries for the various tools ... see the default config files)
// has individual boolean settings turning on or off the writing out of the
// various fields in the netcdf output file for the tool.  Setting all
// dictionary entries to false means the netcdf file will not be generated.
//
// "nc_pairs_flag" can also be set to a boolean value.  In this case, a value
// of true means to just accept the default settings (which will turn on
// the output of all the different fields).  A value of false means no
// netcdf output will be generated.
//
nc_pairs_flag = TRUE;

//
// The "ps_plot_flag" entry is a boolean value for Wavelet-Stat and MODE
// indicating whether a PostScript plot should be generated summarizing
// the verification.
ps_plot_flag = TRUE;

//
// The "rank_corr_flag" entry is a boolean to indicate whether Kendall's Tau
// and Spearman's Rank Correlation Coefficients (in the CNT line type) should
// be computed.  Computing them over large datasets is computationally
// intensive and slows down the runtime significantly.
rank_corr_flag = FALSE;

//
// The "duplicate_flag" entry specifies how to handle duplicate point
// observations in Point-Stat and Ensemble-Stat.  Three techniques are
// currently supported:
//
//    - "NONE" to use all point observations (legacy behavior)
//    - "UNIQUE" if two or more observations match identically except in the
//       station ID field, only use a single observation
//    - "SINGLE" if two or more observations appear at a single location
//      (lat, lon, level, elv), use only the observation that has the valid
//      time closest to the forecast valid time
//
// The reporting mechanism for this feature can be activated by specifying
// a verbosity level of three or higher.  The report will show information
// about where duplicates were detected and which observations were used
// in those cases.
//
duplicate_flag = NONE;

//
// The "obs_quality" entry specifies the quality flag values that are to be
// retained and used for verification.  An empty list signifies that all
// point observations should be used, regardless of their quality flag value.
// The quality flag values will vary depending on the original source of the
// observations.  The quality flag values to retain should be specified as
// an array of strings, even if the values themselves are numeric.
//
obs_quality = [ "1", "2", "3", "9" ];

//
// The "met_data_dir" entry specifies the location of the internal MET data
// sub-directory which contains data files used when generating plots.
//
met_data_dir = "MET_BASE";

//
// The "fcst_raw_plot" entry is a dictionary used by Wavelet-Stat and MODE
// containing colortable plotting information for the plotting of the raw
// forecast field:
//
//    - The "color_table" entry specifies the location and name of the colortable file.
//
//    - The "plot_min" and "plot_max" entries specify the range of data values.
//      If they are both set to 0, the MET tools will automatically rescale
//      the colortable to the range of values present in the data.  If they
//      are not both set to 0, the MET tools will rescale the colortable using
//      their values.
//
fcst_raw_plot = {
   color_table = "MET_BASE/colortables/met_default.ctable";
   plot_min = 0.0;
   plot_max = 0.0;
};

//
// The "obs_raw_plot", "wvlt_plot", and "object_plot" entries are dictionaries
// similar to the "fcst_raw_plot" described above.
//

//
// The "tmp_dir" entry is a string specifying the location where temporary
// files should be written.
//
tmp_dir = "/tmp";

//
// The "output_prefix" entry specifies a string to be included in the output
// file name.  The MET statistics tools construct output file names that
// include the tool name and timing information.  You can use this setting
// to modify the output file name and avoid naming conflicts for multiple runs
// of the same tool.
//
output_prefix  = "";

//
// The "version" entry specifies the version number of the configuration file.
// The configuration file version number should match the version number of
// the MET code being run.  This value should generally not be modified.
//
version = "V5.1";

////////////////////////////////////////////////////////////////////////////////

